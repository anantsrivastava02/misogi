{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anant\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import uuid\n",
    "import openai\n",
    "import pinecone\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Links:\n",
      "0: https://www.example.com/tutorial. (appeared at position 36)\n",
      "1: www.example.org/details (appeared at position 95)\n",
      "2: https://docs.example.net/guide. (appeared at position 150)\n",
      "\n",
      "Clean Text:\n",
      "\n",
      "Check out this awesome tutorial at  \n",
      "For more details, visit  and read \n",
      "the documentation at \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_links(article_text):\n",
    "    link_pattern = r'(https?://[^\\s]+|www\\.[^\\s]+\\.[^\\s]+)'\n",
    "    links = re.finditer(link_pattern, article_text)\n",
    "    links_dict = {}\n",
    "    clean_text = article_text\n",
    "    offset = 0\n",
    "    for i, match in enumerate(links):\n",
    "        link = match.group(0)\n",
    "        start = match.start() - offset\n",
    "        end = match.end() - offset\n",
    "        links_dict[i] = {\n",
    "            'link': link,\n",
    "            'original_position': match.start(),\n",
    "            'length': len(link)\n",
    "        }\n",
    "        clean_text = clean_text[:start] + clean_text[end:]\n",
    "        offset += (end - start)\n",
    "    \n",
    "    return links_dict, clean_text\n",
    "\n",
    "sample_article = \"\"\"\n",
    "Check out this awesome tutorial at https://www.example.com/tutorial. \n",
    "For more details, visit www.example.org/details and read \n",
    "the documentation at https://docs.example.net/guide.\n",
    "\"\"\"\n",
    "\n",
    "links_dict, clean_text = extract_links(sample_article)\n",
    "\n",
    "print(\"Extracted Links:\")\n",
    "for idx, link_info in links_dict.items():\n",
    "    print(f\"{idx}: {link_info['link']} (appeared at position {link_info['original_position']})\")\n",
    "\n",
    "print(\"\\nClean Text:\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting up WebDriver: Could not reach host. Are you offline?\n",
      "Failed to set up WebDriver. Exiting.\n",
      "\n",
      "Scraping Summary:\n",
      "Found 1 links in the article\n",
      "Successfully scraped 0 links\n",
      "Failed to scrape 0 links\n"
     ]
    }
   ],
   "source": [
    "def setup_webdriver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\")\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up WebDriver: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def scrape_url_content(driver, url):\n",
    "    if url.startswith('www.'):\n",
    "        url = 'https://' + url\n",
    "    \n",
    "    result = {\n",
    "        'url': url,\n",
    "        'title': '',\n",
    "        'text_content': '',\n",
    "        'meta_description': '',\n",
    "        'status': 'failed',\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        driver.set_page_load_timeout(30)\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for page to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            result['title'] = driver.title\n",
    "        except:\n",
    "            result['title'] = 'No title found'\n",
    "        \n",
    "        try:\n",
    "            meta_desc = driver.find_element(By.CSS_SELECTOR, \"meta[name='description']\")\n",
    "            result['meta_description'] = meta_desc.get_attribute(\"content\")\n",
    "        except:\n",
    "            result['meta_description'] = 'No meta description found'\n",
    "\n",
    "        main_content = ''\n",
    "        content_selectors = [\n",
    "            \"article\", \"main\", \".content\", \"#content\", \".post-content\", \n",
    "            \".article-content\", \".entry-content\", \"#main-content\"\n",
    "        ]\n",
    "        \n",
    "        for selector in content_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                if elements:\n",
    "                    for elem in elements:\n",
    "                        main_content += elem.text + \"\\n\\n\"\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "        if not main_content.strip():\n",
    "            try:\n",
    "                main_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "            except:\n",
    "                main_content = 'Failed to extract content'\n",
    "        \n",
    "        result['text_content'] = main_content.strip()\n",
    "        result['status'] = 'success'\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except TimeoutException:\n",
    "        result['error'] = 'Page load timeout'\n",
    "        return result\n",
    "    except WebDriverException as e:\n",
    "        result['error'] = f'WebDriver error: {str(e)}'\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result['error'] = f'Unexpected error: {str(e)}'\n",
    "        return result\n",
    "\n",
    "\n",
    "def scrape_links_and_save(links_dict, output_file='scraped_content.json'):\n",
    "    result = {\n",
    "        'links': links_dict,\n",
    "        'scraped_content': {}\n",
    "    }\n",
    "    \n",
    "    driver = setup_webdriver()\n",
    "    if not driver:\n",
    "        print(\"Failed to set up WebDriver. Exiting.\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        for idx, link_info in links_dict.items():\n",
    "            url = link_info['link']\n",
    "            print(f\"Scraping {url}...\")\n",
    "            scraped_data = scrape_url_content(driver, url)\n",
    "            result['scraped_content'][idx] = scraped_data\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "sample_article = \"\"\"https://en.wikipedia.org/wiki/Data_science\"\"\"\n",
    "\n",
    "links_dict, clean_text = extract_links(sample_article)\n",
    "results = scrape_links_and_save(links_dict, 'scraped_content_1.json')\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nScraping Summary:\")\n",
    "print(f\"Found {len(results['links'])} links in the article\")\n",
    "print(f\"Successfully scraped {sum(1 for item in results['scraped_content'].values() if item['status'] == 'success')} links\")\n",
    "print(f\"Failed to scrape {sum(1 for item in results['scraped_content'].values() if item['status'] == 'failed')} links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting up WebDriver: Could not reach host. Are you offline?\n",
      "Failed to set up WebDriver. Exiting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_url_link(driver, url):\n",
    "    if url.startswith('www.'):\n",
    "        url = 'https://' + url\n",
    "    \n",
    "    result = {\n",
    "        'url': url,\n",
    "        'title': '',\n",
    "        'text_content': '',\n",
    "        'meta_description': '',\n",
    "        'links': [],  # New field to store all links found on the page\n",
    "        'status': 'failed',\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Set page load timeout to 30 seconds\n",
    "        driver.set_page_load_timeout(30)\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for page to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            result['title'] = driver.title\n",
    "        except:\n",
    "            result['title'] = 'No title found'\n",
    "        try:\n",
    "            meta_desc = driver.find_element(By.CSS_SELECTOR, \"meta[name='description']\")\n",
    "            result['meta_description'] = meta_desc.get_attribute(\"content\")\n",
    "        except:\n",
    "            result['meta_description'] = 'No meta description found'\n",
    "        try:\n",
    "            link_elements = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "            extracted_links = []\n",
    "            for link in link_elements:\n",
    "                href = link.get_attribute(\"href\")\n",
    "                text = link.text.strip()\n",
    "                \n",
    "                if href and href.startswith(('http://', 'https://', 'www.')):\n",
    "                    extracted_links.append({\n",
    "                        'url': href,\n",
    "                        'text': text if text else 'No link text',\n",
    "                        'title': link.get_attribute(\"title\") or ''\n",
    "                    })\n",
    "            \n",
    "            result['links'] = extracted_links\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting links: {e}\")\n",
    "            result['links'] = []\n",
    "        \n",
    "        # Extract main content - multiple strategies\n",
    "        # Strategy 1: Try to find main content element\n",
    "        main_content = ''\n",
    "        content_selectors = [\n",
    "            \"article\", \"main\", \".content\", \"#content\", \".post-content\", \n",
    "            \".article-content\", \".entry-content\", \"#main-content\"\n",
    "        ]\n",
    "        \n",
    "        for selector in content_selectors:\n",
    "            try:\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                if elements:\n",
    "                    for elem in elements:\n",
    "                        main_content += elem.text + \"\\n\\n\"\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Strategy 2: If no main content found, get the body text\n",
    "        if not main_content.strip():\n",
    "            try:\n",
    "                main_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "            except:\n",
    "                main_content = 'Failed to extract content'\n",
    "        \n",
    "        result['text_content'] = main_content.strip()\n",
    "        result['status'] = 'success'\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except TimeoutException:\n",
    "        result['error'] = 'Page load timeout'\n",
    "        return result\n",
    "    except WebDriverException as e:\n",
    "        result['error'] = f'WebDriver error: {str(e)}'\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result['error'] = f'Unexpected error: {str(e)}'\n",
    "        return result\n",
    "\n",
    "\n",
    "def scrape_links_and_save(article_text, output_file='scraped_content.json'):\n",
    "    links_dict, clean_text = extract_links(article_text)\n",
    "    result = {\n",
    "        'original_text': article_text,\n",
    "        'clean_text': clean_text,\n",
    "        'links': links_dict,\n",
    "        'scraped_content': {}\n",
    "    }\n",
    "\n",
    "    driver = setup_webdriver()\n",
    "    if not driver:\n",
    "        print(\"Failed to set up WebDriver. Exiting.\")\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        for idx, link_info in links_dict.items():\n",
    "            url = link_info['link']\n",
    "            print(f\"Scraping {url}...\")\n",
    "            \n",
    "            # Scrape the URL\n",
    "            scraped_data = scrape_url_link(driver, url)\n",
    "            \n",
    "            # Add scraped content to results\n",
    "            result['scraped_content'][idx] = scraped_data\n",
    "            \n",
    "            # Add a short delay between requests to be polite\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Save results to JSON file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"Results saved to {output_file}\")\n",
    "        \n",
    "    finally:\n",
    "        # Always close the WebDriver\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "sample_article = \"\"\"https://en.wikipedia.org/wiki/Data_science\"\"\"\n",
    "\n",
    "# Scrape the links and save results\n",
    "results = scrape_links_and_save(sample_article, 'scraped_content.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import pinecone\n",
    "import openai\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = \"\"\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENVIRONMENT = \"us-east1-gcp\"\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\") or \"scraped-content\"\n",
    "\n",
    "# Model parameters\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"  \n",
    "EMBEDDING_DIMENSION = 1536  \n",
    "CHUNK_SIZE = 1000  \n",
    "CHUNK_OVERLAP = 200  \n",
    "MAX_CHUNKS_PER_BATCH = 100  \n",
    "\n",
    "\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone client and ensure index exists.\"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone client\n",
    "        pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "        # Check if index already exists\n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "\n",
    "        if PINECONE_INDEX_NAME not in existing_indexes:\n",
    "            print(f\"Creating Pinecone index: {PINECONE_INDEX_NAME}\")\n",
    "            pc.create_index(\n",
    "                name=PINECONE_INDEX_NAME,\n",
    "                dimension=EMBEDDING_DIMENSION,\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",       # Specify cloud provider (e.g., 'aws' or 'gcp')\n",
    "                    region=\"us-east-1\" # Specify region (e.g., 'us-east-1' for AWS)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Poll until index is ready\n",
    "            max_attempts = 12\n",
    "            attempt = 0\n",
    "            while attempt < max_attempts:\n",
    "                try:\n",
    "                    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "                    index.describe_index_stats()  # Test if index is accessible\n",
    "                    print(f\"Index {PINECONE_INDEX_NAME} is ready.\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    attempt += 1\n",
    "                    if attempt == max_attempts:\n",
    "                        raise Exception(f\"Index {PINECONE_INDEX_NAME} not ready after {max_attempts * 5} seconds.\")\n",
    "                    print(f\"Waiting for index to be ready... ({attempt}/{max_attempts})\")\n",
    "                    time.sleep(5)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Index {PINECONE_INDEX_NAME} already exists.\")\n",
    "\n",
    "        # Return the index object\n",
    "        return pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to initialize Pinecone: {str(e)}\")\n",
    "\n",
    "def clean_and_chunk_text(text: str, chunk_size: int = CHUNK_SIZE, chunk_overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
    "    \"\"\"Clean and split text into chunks of specified size with overlap\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    \n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        if end < text_length:\n",
    "            if text[end-1] not in \".,!? \":\n",
    "                last_period = text.rfind('.', start, end)\n",
    "                last_space = text.rfind(' ', start, end)\n",
    "                if last_period > start + (chunk_size // 2):\n",
    "                    end = last_period + 1\n",
    "                elif last_space > start + (chunk_size // 2):\n",
    "                    end = last_space + 1\n",
    "        \n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:  # Only add non-empty chunks\n",
    "            chunks.append(chunk)\n",
    "        start = end - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "def get_embeddings(chunks: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Get embeddings for chunks using OpenAI's embedding API\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(chunks), MAX_CHUNKS_PER_BATCH):\n",
    "        batch = chunks[i:i + MAX_CHUNKS_PER_BATCH]\n",
    "        try:\n",
    "            response = openai.embeddings.create(\n",
    "                model=EMBEDDING_MODEL,\n",
    "                input=batch\n",
    "            )\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            if i + MAX_CHUNKS_PER_BATCH < len(chunks):\n",
    "                time.sleep(0.5) \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embeddings: {e}\")\n",
    "            embeddings.extend([[0] * EMBEDDING_DIMENSION] * len(batch))\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def process_json_file(file_path: str):\n",
    "    \"\"\"Process scraped content JSON file and ingest into Pinecone\"\"\"\n",
    "    print(f\"Loading scraped content from {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize Pinecone\n",
    "    index = initialize_pinecone()\n",
    "    \n",
    "    # Extract and process original article\n",
    "    print(\"Processing original article...\")\n",
    "    article_text = data.get('original_text', '')\n",
    "    article_chunks = clean_and_chunk_text(article_text)\n",
    "    \n",
    "    all_chunks = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    # Process original article chunks\n",
    "    for i, chunk in enumerate(article_chunks):\n",
    "        chunk_id = f\"original_article_{i}\"\n",
    "        all_chunks.append(chunk)\n",
    "        all_metadata.append({\n",
    "            \"id\": chunk_id,\n",
    "            \"type\": \"original_article\",\n",
    "            \"chunk_index\": i,\n",
    "            \"total_chunks\": len(article_chunks),\n",
    "            \"source\": \"original_article\"\n",
    "        })\n",
    "    \n",
    "    scraped_content = data.get('scraped_content', {})\n",
    "    print(f\"Processing {len(scraped_content)} scraped pages...\")\n",
    "    \n",
    "    for page_id, page_data in scraped_content.items():\n",
    "        if page_data.get('status') != 'success':\n",
    "            continue\n",
    "        \n",
    "        # Get page content\n",
    "        url = page_data.get('url', '')\n",
    "        title = page_data.get('title', '')\n",
    "        text_content = page_data.get('text_content', '')\n",
    "        \n",
    "        # Skip if no substantial content\n",
    "        if len(text_content) < 50:\n",
    "            continue\n",
    "        \n",
    "        # Chunk page content\n",
    "        page_chunks = clean_and_chunk_text(text_content)\n",
    "        \n",
    "        # Process page chunks\n",
    "        for i, chunk in enumerate(page_chunks):\n",
    "            chunk_id = f\"page_{page_id}_chunk_{i}\"\n",
    "            all_chunks.append(chunk)\n",
    "            all_metadata.append({\n",
    "                \"id\": chunk_id,\n",
    "                \"type\": \"scraped_page\",\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(page_chunks),\n",
    "                \"page_id\": page_id\n",
    "            })\n",
    "            \n",
    "         \n",
    "            if i == 0 and page_data.get('links'):  # Only store links with first chunk\n",
    "                link_texts = []\n",
    "                for link in page_data.get('links', []):\n",
    "                    link_url = link.get('url', '')\n",
    "                    link_text = link.get('text', '')\n",
    "                    if link_url and link_text:\n",
    "                        link_texts.append(f\"{link_text}: {link_url}\")\n",
    "                \n",
    "                if link_texts:\n",
    "                    links_text = \"Links found on page:\\n\" + \"\\n\".join(link_texts)\n",
    "                    links_chunks = clean_and_chunk_text(links_text)\n",
    "                    \n",
    "                    for j, link_chunk in enumerate(links_chunks):\n",
    "                        chunk_id = f\"page_{page_id}_links_{j}\"\n",
    "                        all_chunks.append(link_chunk)\n",
    "                        all_metadata.append({\n",
    "                            \"id\": chunk_id,\n",
    "                            \"type\": \"page_links\",\n",
    "                            \"url\": url,\n",
    "                            \"title\": title + \" - Links\",\n",
    "                            \"chunk_index\": j,\n",
    "                            \"total_chunks\": len(links_chunks),\n",
    "                            \"page_id\": page_id\n",
    "                        })\n",
    "    \n",
    "    # Get embeddings for all chunks\n",
    "    print(f\"Generating embeddings for {len(all_chunks)} chunks...\")\n",
    "    embeddings = get_embeddings(all_chunks)\n",
    "    \n",
    "    # Prepare vectors for Pinecone\n",
    "    vectors = []\n",
    "    for i, (chunk, embedding, metadata) in enumerate(zip(all_chunks, embeddings, all_metadata)):\n",
    "        vector_id = str(uuid.uuid4())\n",
    "        vectors.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": {\n",
    "                **metadata,\n",
    "                \"text\": chunk[:1000],  # Store truncated text in metadata\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Upsert in batches of 100\n",
    "        if len(vectors) >= 100 or i == len(all_chunks) - 1:\n",
    "            print(f\"Upserting batch of {len(vectors)} vectors to Pinecone...\")\n",
    "            index.upsert(vectors=vectors)\n",
    "            vectors = []\n",
    "    \n",
    "    print(\"Ingestion complete!\")\n",
    "    return len(all_chunks)\n",
    "\n",
    "def query_similar_content(query_text: str, top_k: int = 5):\n",
    "    \"\"\"Query Pinecone for similar content based on the query text\"\"\"\n",
    "    # Initialize Pinecone\n",
    "    pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_embedding = get_embeddings([query_text])[0]\n",
    "    \n",
    "    # Query Pinecone\n",
    "    query_results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    # Process and return results\n",
    "    results = []\n",
    "    for match in query_results.matches:\n",
    "        results.append({\n",
    "            \"score\": match.score,\n",
    "            \"text\": match.metadata.get(\"text\", \"\"),\n",
    "            \"source\": match.metadata.get(\"url\", match.metadata.get(\"source\", \"\")),\n",
    "            \"title\": match.metadata.get(\"title\", \"\")\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "        # Ingest content\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\anant\\anaconda3\\lib\\site-packages (0.28.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.9.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\anant\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anant\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\anant\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\anant\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
      "   ---------------------------------------- 0.0/683.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 683.3/683.3 kB 5.4 MB/s eta 0:00:00\n",
      "Using cached jiter-0.9.0-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "Successfully installed jiter-0.9.0 openai-1.79.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~oetry (C:\\Users\\anant\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oetry (C:\\Users\\anant\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oetry (C:\\Users\\anant\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.14 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.3.60 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import re\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from openai import OpenAI  # Use the updated OpenAI client\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENVIRONMENT = \"us-east1-gcp\"\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\") or \"scraped-content\"\n",
    "\n",
    "# Model parameters\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "EMBEDDING_DIMENSION = 1536\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "MAX_CHUNKS_PER_BATCH = 100\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def get_embeddings(chunks: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Get embeddings for chunks using OpenAI's embedding API.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(chunks), MAX_CHUNKS_PER_BATCH):\n",
    "        batch = chunks[i:i + MAX_CHUNKS_PER_BATCH]\n",
    "        try:\n",
    "            response = openai_client.embeddings.create(\n",
    "                model=EMBEDDING_MODEL,\n",
    "                input=batch\n",
    "            )\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            # Ensure embeddings are floats\n",
    "            batch_embeddings = [[float(x) for x in embedding] for embedding in batch_embeddings]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "            if i + MAX_CHUNKS_PER_BATCH < len(chunks):\n",
    "                time.sleep(0.5)  # Avoid rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embeddings: {e}\")\n",
    "            # Return zero embeddings for failed batch to maintain alignment\n",
    "            embeddings.extend([[0.0] * EMBEDDING_DIMENSION] * len(batch))\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def process_json_file(file_path: str):\n",
    "    \"\"\"Process scraped content JSON file and ingest into Pinecone.\"\"\"\n",
    "    print(f\"Loading scraped content from {file_path}\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to load JSON file: {e}\")\n",
    "\n",
    "    # Initialize Pinecone\n",
    "    index = initialize_pinecone()\n",
    "    \n",
    "    # Extract and process original article\n",
    "    print(\"Processing original article...\")\n",
    "    article_text = data.get('original_text', '')\n",
    "    article_chunks = clean_and_chunk_text(article_text)\n",
    "    \n",
    "    all_chunks = []\n",
    "    all_metadata = []\n",
    "    \n",
    "    # Process original article chunks\n",
    "    for i, chunk in enumerate(article_chunks):\n",
    "        chunk_id = f\"original_article_{i}\"\n",
    "        all_chunks.append(chunk)\n",
    "        all_metadata.append({\n",
    "            \"id\": chunk_id,\n",
    "            \"type\": \"original_article\",\n",
    "            \"chunk_index\": i,\n",
    "            \"total_chunks\": len(article_chunks),\n",
    "            \"source\": \"original_article\"\n",
    "        })\n",
    "    \n",
    "    scraped_content = data.get('scraped_content', {})\n",
    "    print(f\"Processing {len(scraped_content)} scraped pages...\")\n",
    "    \n",
    "    for page_id, page_data in scraped_content.items():\n",
    "        if page_data.get('status') != 'success':\n",
    "            continue\n",
    "        \n",
    "        # Get page content\n",
    "        url = page_data.get('url', '')\n",
    "        title = page_data.get('title', '')\n",
    "        text_content = page_data.get('text_content', '')\n",
    "        \n",
    "        # Skip if no substantial content\n",
    "        if len(text_content) < 50:\n",
    "            continue\n",
    "        \n",
    "        # Chunk page content\n",
    "        page_chunks = clean_and_chunk_text(text_content)\n",
    "        \n",
    "        # Process page chunks\n",
    "        for i, chunk in enumerate(page_chunks):\n",
    "            chunk_id = f\"page_{page_id}_chunk_{i}\"\n",
    "            all_chunks.append(chunk)\n",
    "            all_metadata.append({\n",
    "                \"id\": chunk_id,\n",
    "                \"type\": \"scraped_page\",\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(page_chunks),\n",
    "                \"page_id\": page_id\n",
    "            })\n",
    "            \n",
    "            if i == 0 and page_data.get('links'):  # Only store links with first chunk\n",
    "                link_texts = []\n",
    "                for link in page_data.get('links', []):\n",
    "                    link_url = link.get('url', '')\n",
    "                    link_text = link.get('text', '')\n",
    "                    if link_url and link_text:\n",
    "                        link_texts.append(f\"{link_text}: {link_url}\")\n",
    "                \n",
    "                if link_texts:\n",
    "                    links_text = \"Links found on page:\\n\" + \"\\n\".join(link_texts)\n",
    "                    links_chunks = clean_and_chunk_text(links_text)\n",
    "                    \n",
    "                    for j, link_chunk in enumerate(links_chunks):\n",
    "                        chunk_id = f\"page_{page_id}_links_{j}\"\n",
    "                        all_chunks.append(link_chunk)\n",
    "                        all_metadata.append({\n",
    "                            \"id\": chunk_id,\n",
    "                            \"type\": \"page_links\",\n",
    "                            \"url\": url,\n",
    "                            \"title\": title + \" - Links\",\n",
    "                            \"chunk_index\": j,\n",
    "                            \"total_chunks\": len(links_chunks),\n",
    "                            \"page_id\": page_id\n",
    "                        })\n",
    "    \n",
    "    # Get embeddings for all chunks\n",
    "    print(f\"Generating embeddings for {len(all_chunks)} chunks...\")\n",
    "    embeddings = get_embeddings(all_chunks)\n",
    "    \n",
    "    # Prepare vectors for Pinecone\n",
    "    vectors = []\n",
    "    for i, (chunk, embedding, metadata) in enumerate(zip(all_chunks, embeddings, all_metadata)):\n",
    "        vector_id = str(uuid.uuid4())\n",
    "        vectors.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,  # Already ensured to be floats\n",
    "            \"metadata\": {\n",
    "                **metadata,\n",
    "                \"text\": chunk[:1000],  # Store truncated text in metadata\n",
    "                \"timestamp\": time.time()\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Upsert in batches of 100 or at the end\n",
    "        if len(vectors) >= 100 or i == len(all_chunks) - 1:\n",
    "            print(f\"Upserting batch of {len(vectors)} vectors to Pinecone...\")\n",
    "            try:\n",
    "                index.upsert(vectors=vectors)\n",
    "                vectors = []\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to upsert batch: {e}\")\n",
    "                raise\n",
    "    \n",
    "    print(\"Ingestion complete!\")\n",
    "    return len(all_chunks)\n",
    "\n",
    "# Other functions (initialize_pinecone, clean_and_chunk_text, query_similar_content) remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scraped content from C:\\Users\\anant\\Misogi\\scraped_content.json\n",
      "Index scraped-content already exists.\n",
      "Processing original article...\n",
      "Processing 1 scraped pages...\n",
      "Generating embeddings for 74 chunks...\n",
      "Upserting batch of 74 vectors to Pinecone...\n",
      "Ingestion complete!\n",
      "Successfully processed 74 chunks\n",
      "No results found for query: What is data Science?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define file path and query directly\n",
    "file_path = Path(\"C:/Users/anant/Misogi/scraped_content.json\")  # Use forward slashes for cross-platform compatibility\n",
    "query = \"What is data Science?\"  # Corrected typo\n",
    "\n",
    "# Process the JSON file\n",
    "try:\n",
    "    chunks_processed = process_json_file(file_path)\n",
    "    print(f\"Successfully processed {chunks_processed} chunks\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to process file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Query similar content\n",
    "try:\n",
    "    results = query_similar_content(query)\n",
    "    if not results:\n",
    "        print(f\"No results found for query: {query}\")\n",
    "    else:\n",
    "        print(\"\\nSearch Results:\")\n",
    "        for i, result in enumerate(results, 1):  # Start enumeration at 1\n",
    "            title = result.get('title', 'No title')  # Safe access with default\n",
    "            score = result.get('score', 0.0)\n",
    "            source = result.get('source', 'No source')\n",
    "            text = result.get('text', '')[:200]  # Safe truncation\n",
    "            print(f\"\\n{i}. {title} (Score: {score:.4f})\")\n",
    "            print(f\"Source: {source}\")\n",
    "            print(f\"Content: {text}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error querying content: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import pinecone\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import wave\n",
    "import tempfile\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import speech_recognition as sr \n",
    "import threading\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice RAG Assistant Starting...\n",
      "Make sure your Pinecone index has been populated with your scraped content.\n",
      "Index scraped-content already exists.\n",
      "Connected to Pinecone successfully!\n",
      "\n",
      "==================================================\n",
      "Press Enter to ask a question (or type 'exit' to quit)\n",
      "Recording for 5 seconds...\n",
      ".....\n",
      "Recording complete!\n",
      "Transcribing...\n",
      "Transcription: hello hello hello hello hello hello hello hello\n",
      "Processing question: hello hello hello hello hello hello hello hello\n",
      "Searching knowledge base...\n",
      "Generating answer...\n",
      "Answer: I'm here to assist you with any questions you may have. How can I help you today?\n",
      "Converting answer to speech...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anant\\AppData\\Local\\Temp\\ipykernel_28044\\3774697910.py:105: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(output_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to response.wav\n",
      "Playing response...\n",
      "\n",
      "==================================================\n",
      "Press Enter to ask a question (or type 'exit' to quit)\n",
      "Recording for 5 seconds...\n",
      ".....\n",
      "Recording complete!\n",
      "Transcribing...\n",
      "Transcription: hello hello hello hello hello how are you\n",
      "Processing question: hello hello hello hello hello how are you\n",
      "Searching knowledge base...\n",
      "Generating answer...\n",
      "Answer: I'm here and ready to assist you! How can I help you today?\n",
      "Converting answer to speech...\n",
      "Speech saved to response.wav\n",
      "Playing response...\n",
      "\n",
      "==================================================\n",
      "Press Enter to ask a question (or type 'exit' to quit)\n",
      "Recording for 5 seconds...\n",
      ".....\n",
      "Recording complete!\n",
      "Transcribing...\n",
      "Transcription: Good morning.\n",
      "Processing question: Good morning.\n",
      "Searching knowledge base...\n",
      "Generating answer...\n",
      "Answer: Good morning! How can I assist you today?\n",
      "Converting answer to speech...\n",
      "Speech saved to response.wav\n",
      "Playing response...\n",
      "\n",
      "==================================================\n",
      "Press Enter to ask a question (or type 'exit' to quit)\n",
      "Recording for 5 seconds...\n",
      ".....\n",
      "Recording complete!\n",
      "Transcribing...\n",
      "Transcription: \n",
      "Sorry, I couldn't understand that. Please try again.\n",
      "\n",
      "==================================================\n",
      "Press Enter to ask a question (or type 'exit' to quit)\n",
      "Recording for 5 seconds...\n",
      ".....\n",
      "Recording complete!\n",
      "Transcribing...\n",
      "Transcription: . \n",
      "Processing question: . \n",
      "Searching knowledge base...\n",
      "Generating answer...\n",
      "Answer: I'm sorry, but I couldn't find a specific question in your input. How can I assist you today?\n",
      "Converting answer to speech...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 183\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     voice_assistant()\n",
      "Cell \u001b[1;32mIn[11], line 172\u001b[0m, in \u001b[0;36mvoice_assistant\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Convert answer to speech\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting answer to speech...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m speech_file \u001b[38;5;241m=\u001b[39m text_to_speech(answer)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m speech_file:\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# Play the response\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlaying response...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 98\u001b[0m, in \u001b[0;36mtext_to_speech\u001b[1;34m(text, output_file)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert text to speech using OpenAI's TTS API\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Generate speech using OpenAI's TTS\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspeech\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     99\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts-1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    100\u001b[0m         voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malloy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtext\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Save to file\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     response\u001b[38;5;241m.\u001b[39mstream_to_file(output_file)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\openai\\resources\\audio\\speech.py:99\u001b[0m, in \u001b[0;36mSpeech.create\u001b[1;34m(self, input, model, voice, instructions, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/audio/speech\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    102\u001b[0m         {\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoice\u001b[39m\u001b[38;5;124m\"\u001b[39m: voice,\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m\"\u001b[39m: speed,\n\u001b[0;32m    109\u001b[0m         },\n\u001b[0;32m    110\u001b[0m         speech_create_params\u001b[38;5;241m.\u001b[39mSpeechCreateParams,\n\u001b[0;32m    111\u001b[0m     ),\n\u001b[0;32m    112\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    113\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    114\u001b[0m     ),\n\u001b[0;32m    115\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39m_legacy_response\u001b[38;5;241m.\u001b[39mHttpxBinaryResponseContent,\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    927\u001b[0m     request,\n\u001b[0;32m    928\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    929\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    930\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    955\u001b[0m         request,\n\u001b[0;32m    956\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    957\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\anant\\anaconda3\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "OUTPUT_FILENAME = \"response.wav\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "def record_audio(duration=RECORD_SECONDS):\n",
    "    \"\"\"Record audio from microphone\"\"\"\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "    \n",
    "    # Record audio\n",
    "    audio_data = sd.rec(int(SAMPLE_RATE * duration), samplerate=SAMPLE_RATE, channels=1, dtype='int16')\n",
    "    for _ in range(duration):\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(1)\n",
    "    print(\"\\nRecording complete!\")\n",
    "    \n",
    "    sd.wait()  \n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    temp_filename = temp_file.name\n",
    "    temp_file.close()\n",
    "    \n",
    "    with wave.open(temp_filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)  # 16-bit audio\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "    \n",
    "    return temp_filename\n",
    "\n",
    "def speech_to_text(audio_file_path):\n",
    "    \"\"\"Convert speech to text using speech recognition\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    try:\n",
    "        with sr.AudioFile(audio_file_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            print(\"Transcribing...\")\n",
    "            \n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "            except:\n",
    "                # Fall back to OpenAI's Whisper API\n",
    "                with open(audio_file_path, \"rb\") as audio_file:\n",
    "                    response = openai.audio.transcriptions.create(\n",
    "                        model=\"whisper-1\",\n",
    "                        file=audio_file\n",
    "                    )\n",
    "                    text = response.text\n",
    "            \n",
    "            print(f\"Transcription: {text}\")\n",
    "            return text\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\"\n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        try:\n",
    "            os.remove(audio_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def generate_answer(query, context_data):\n",
    "    \"\"\"Generate answer using GPT-3.5 with context from RAG\"\"\"\n",
    "    context = \"\"\n",
    "    for i, item in enumerate(context_data):\n",
    "        context += f\"\\nSOURCE {i+1} ({item['title']}):\\n{item['text']}\\n\"\n",
    "    \n",
    "    # Create prompt for GPT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"You are a helpful voice assistant that provides informative answers based on retrieved content. \"\n",
    "            \"Use the provided context to answer the user's question. \"\n",
    "            \"If the context doesn't contain relevant information, say so politely. \"\n",
    "            \"Keep answers concise and conversational, suitable for voice responses. \"\n",
    "            \"Don't reference 'context' or 'sources' directly in your answer.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": f\"CONTEXT: {context}\\n\\nQUESTION: {query}\\n\\nPlease provide a helpful answer:\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return \"I'm sorry, I wasn't able to generate an answer. Please try again.\"\n",
    "\n",
    "def text_to_speech(text, output_file=OUTPUT_FILENAME):\n",
    "    \"\"\"Convert text to speech using OpenAI's TTS API\"\"\"\n",
    "    try:\n",
    "        # Generate speech using OpenAI's TTS\n",
    "        response = openai.audio.speech.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"alloy\",\n",
    "            input=text\n",
    "        )\n",
    "        \n",
    "        # Save to file\n",
    "        response.stream_to_file(output_file)\n",
    "        print(f\"Speech saved to {output_file}\")\n",
    "        \n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting text to speech: {e}\")\n",
    "        return None\n",
    "\n",
    "def play_audio(file_path):\n",
    "    \"\"\"Play audio file\"\"\"\n",
    "    try:\n",
    "        data, fs = sf.read(file_path)\n",
    "        sd.play(data, fs)\n",
    "        status = sd.wait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")\n",
    "\n",
    "def voice_assistant():\n",
    "    \"\"\"Main voice assistant function\"\"\"\n",
    "    print(\"Voice RAG Assistant Starting...\")\n",
    "    print(\"Make sure your Pinecone index has been populated with your scraped content.\")\n",
    "    \n",
    "    # Initialize Pinecone\n",
    "    try:\n",
    "        initialize_pinecone()\n",
    "        print(\"Connected to Pinecone successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Pinecone: {e}\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Press Enter to ask a question (or type 'exit' to quit)\")\n",
    "        user_input = input()\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Thank you for using Voice RAG Assistant. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Record audio\n",
    "            audio_file = record_audio()\n",
    "            \n",
    "            # Convert speech to text\n",
    "            query = speech_to_text(audio_file)\n",
    "            \n",
    "            if not query:\n",
    "                print(\"Sorry, I couldn't understand that. Please try again.\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing question: {query}\")\n",
    "            \n",
    "            # Query for similar content\n",
    "            print(\"Searching knowledge base...\")\n",
    "            search_results = query_similar_content(query, top_k=3)\n",
    "            \n",
    "            if not search_results:\n",
    "                answer = \"I couldn't find any relevant information in my knowledge base.\"\n",
    "            else:\n",
    "                # Generate answer using GPT with context\n",
    "                print(\"Generating answer...\")\n",
    "                answer = generate_answer(query, search_results)\n",
    "            \n",
    "            print(f\"Answer: {answer}\")\n",
    "            \n",
    "            # Convert answer to speech\n",
    "            print(\"Converting answer to speech...\")\n",
    "            speech_file = text_to_speech(answer)\n",
    "            \n",
    "            if speech_file:\n",
    "                # Play the response\n",
    "                print(\"Playing response...\")\n",
    "                play_audio(speech_file)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    voice_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import wave\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "CARTESIA_API_KEY = os.getenv(\"CARTESIA_API_KEY\") or \"sk_car_ZJkw9b4W43vXvtNuEh7sFi\"  # Replace with your key or use .env\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") or \"your-openai-api-key-here\"  # Replace or use .env\n",
    "SAMPLE_RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "OUTPUT_FILENAME = \"response.wav\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def text_to_speech(text, output_file=OUTPUT_FILENAME):\n",
    "    \"\"\"Convert text to speech using Cartesia's TTS API.\"\"\"\n",
    "    try:\n",
    "        url = \"https://api.cartesia.ai/tts/bytes\"\n",
    "        headers = {\n",
    "            \"Cartesia-Version\": \"2024-06-10\",\n",
    "            \"X-API-Key\": CARTESIA_API_KEY,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"model_id\": \"sonic-2\",\n",
    "            \"transcript\": text,\n",
    "            \"voice\": {\n",
    "                \"mode\": \"id\",\n",
    "                \"id\": \"bf0a246a-8642-498a-9950-80c35e9276b5\"\n",
    "            },\n",
    "            \"output_format\": {\n",
    "                \"container\": \"wav\",\n",
    "                \"encoding\": \"pcm_f32le\",\n",
    "                \"sample_rate\": 44100\n",
    "            },\n",
    "            \"language\": \"en\"\n",
    "        }\n",
    "\n",
    "        # Send POST request to Cartesia API\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "\n",
    "        # Save binary audio response to WAV file\n",
    "        output_path = Path(output_file)\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(f\"Speech saved to {output_file}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting text to speech: {e}\")\n",
    "        return None\n",
    "\n",
    "# Rest of your code (unchanged functions: record_audio, speech_to_text, generate_answer, play_audio, voice_assistant)\n",
    "# Placeholder for required functions to make the artifact complete\n",
    "def record_audio(duration=RECORD_SECONDS):\n",
    "    \"\"\"Record audio from microphone\"\"\"\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "    audio_data = sd.rec(int(SAMPLE_RATE * duration), samplerate=SAMPLE_RATE, channels=1, dtype='int16')\n",
    "    for _ in range(duration):\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(1)\n",
    "    print(\"\\nRecording complete!\")\n",
    "    sd.wait()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    temp_filename = temp_file.name\n",
    "    temp_file.close()\n",
    "    with wave.open(temp_filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(SAMPLE_RATE)\n",
    "        wf.writeframes(audio_data.tobytes())\n",
    "    return temp_filename\n",
    "\n",
    "def speech_to_text(audio_file_path):\n",
    "    \"\"\"Convert speech to text using speech recognition\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(audio_file_path) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            print(\"Transcribing...\")\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "            except:\n",
    "                with open(audio_file_path, \"rb\") as audio_file:\n",
    "                    response = openai_client.audio.transcriptions.create(\n",
    "                        model=\"whisper-1\",\n",
    "                        file=audio_file\n",
    "                    )\n",
    "                    text = response.text\n",
    "            print(f\"Transcription: {text}\")\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return \"\"\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(audio_file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def generate_answer(query, context_data):\n",
    "    \"\"\"Generate answer using GPT-3.5 with context from RAG\"\"\"\n",
    "    context = \"\"\n",
    "    for i, item in enumerate(context_data):\n",
    "        context += f\"\\nSOURCE {i+1} ({item['title']}):\\n{item['text']}\\n\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"You are a helpful voice assistant that provides informative answers based on retrieved content. \"\n",
    "            \"Use the provided context to answer the user's question. \"\n",
    "            \"If the context doesn't contain relevant information, say so politely. \"\n",
    "            \"Keep answers concise and conversational, suitable for voice responses. \"\n",
    "            \"Don't reference 'context' or 'sources' directly in your answer.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": f\"CONTEXT: {context}\\n\\nQUESTION: {query}\\n\\nPlease provide a helpful answer:\"}\n",
    "    ]\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return \"I'm sorry, I wasn't able to generate an answer. Please try again.\"\n",
    "\n",
    "def play_audio(file_path):\n",
    "    \"\"\"Play audio file\"\"\"\n",
    "    try:\n",
    "        data, fs = sf.read(file_path)\n",
    "        sd.play(data, fs)\n",
    "        sd.wait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Placeholder for Pinecone initialization\"\"\"\n",
    "    pass\n",
    "\n",
    "def query_similar_content(query, top_k):\n",
    "    \"\"\"Placeholder for querying similar content\"\"\"\n",
    "    return [{\"title\": \"Sample\", \"text\": \"This is a sample response\"}]\n",
    "\n",
    "def voice_assistant():\n",
    "    \"\"\"Main voice assistant function\"\"\"\n",
    "    print(\"Voice RAG Assistant Starting...\")\n",
    "    print(\"Make sure your Pinecone index has been populated with your scraped content.\")\n",
    "    try:\n",
    "        initialize_pinecone()\n",
    "        print(\"Connected to Pinecone successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Pinecone: {e}\")\n",
    "        return\n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Press Enter to ask a question (or type 'exit' to quit)\")\n",
    "        user_input = input()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Thank you for using Voice RAG Assistant. Goodbye!\")\n",
    "            break\n",
    "        try:\n",
    "            audio_file = record_audio()\n",
    "            query = speech_to_text(audio_file)\n",
    "            if not query:\n",
    "                print(\"Sorry, I couldn't understand that. Please try again.\")\n",
    "                continue\n",
    "            print(f\"Processing question: {query}\")\n",
    "            print(\"Searching knowledge base...\")\n",
    "            search_results = query_similar_content(query, top_k=3)\n",
    "            if not search_results:\n",
    "                answer = \"I couldn't find any relevant information in my knowledge base.\"\n",
    "            else:\n",
    "                print(\"Generating answer...\")\n",
    "                answer = generate_answer(query, search_results)\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(\"Converting answer to speech...\")\n",
    "            speech_file = text_to_speech(answer)\n",
    "            if speech_file:\n",
    "                print(\"Playing response...\")\n",
    "                play_audio(speech_file)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    voice_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
